{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'data/middlebury/images/'\n",
    "out_path = 'data/middlebury/features/'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_image1 = out_path + 'Backyard/frame07.pkl'\n",
    "features_image2 = out_path + 'Backyard/frame08.pkl'\n",
    "image1 = im_path + 'Backyard/frame07.png'\n",
    "image2 = im_path + 'Backyard/frame08.png'\n",
    "\n",
    "features1 = pkl.load( open(features_image1, \"rb\" ) )\n",
    "features2 = pkl.load( open(features_image2, \"rb\" ) )\n",
    "\n",
    "tensor_F1 = torch.from_numpy(features1[\"F\"]).t()\n",
    "tensor_U1 = torch.from_numpy(features1[\"U\"]).t()\n",
    "tensor_F2 = torch.from_numpy(features2[\"F\"]).t()\n",
    "tensor_U2 = torch.from_numpy(features2[\"U\"]).t()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1536])\n"
     ]
    }
   ],
   "source": [
    "class DataLoader(data.Dataset):\n",
    "\tdef __init__(self, data, args, pad_index, shuffle = True):\n",
    "        super(DataLoader).__init__(self):\n",
    "        classes, class_to_idx = self._find_classes(self.root)\n",
    "        samples = self.make_dataset(self.root, class_to_idx, extensions, is_valid_file)\n",
    "        \n",
    "    def make_dataset( self,dir, class_to_idx, extensions=None, is_valid_file=None):\n",
    "    images = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for target in sorted(class_to_idx.keys()):\n",
    "        d = os.path.join(dir, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                if is_valid_file(path):\n",
    "                    item = (path, class_to_idx[target])\n",
    "                    images.append(item)\n",
    "\n",
    "    return images\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        \"\"\"\n",
    "        Finds the class folders in a dataset.\n",
    "        Args:\n",
    "            dir (string): Root directory path.\n",
    "        Returns:\n",
    "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
    "        Ensures:\n",
    "            No class is a subdirectory of another.\n",
    "        \"\"\"\n",
    "        if sys.version_info >= (3, 5):\n",
    "            # Faster and available in Python 3.5 and above\n",
    "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        else:\n",
    "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "\tdef __getitem__(self):\n",
    "        \n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_bn = models.vgg16_bn(pretrained = True)\n",
    "class VGG_graph_matching(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_graph_matching, self).__init__()\n",
    "        self.features1 = nn.Sequential(\n",
    "            *list(vgg_bn.features.children())[:33]\n",
    "        )\n",
    "        self.features2 = nn.Sequential(\n",
    "            *list(vgg_bn.features.children())[33:43]\n",
    "        )\n",
    "                # => TODO: lambda init for trivial test\n",
    "        self.lam = nn.Parameter(torch.ones(20, 2, device = device))\n",
    "    def forward(self, x_1, mask_1, x_2 = None, mask_2 = None):\n",
    "        \n",
    "        x_1 = self.features1(x_1)\n",
    "        U1 = x_1[:,:, mask_1[0]]\n",
    "        x_1 = self.features2(x_1)\n",
    "        F1 =  x_1[:,:, mask_1[1]]\n",
    "        \n",
    "        if x_2 is None:\n",
    "            return U1, F1\n",
    "        \n",
    "        else:\n",
    "            x_2 = self.features1(x_2)\n",
    "            U2 = x_2[:,:, mask_2[0]]\n",
    "            x_2 = self.features2(x_2)\n",
    "            F2 =  x_2[:,:, mask_2[1]]\n",
    "            \n",
    "            test = torch.from_numpy(np.asarray([[1,0,1],[1,1,1],[1,0,0]]))\n",
    "            [G, H] = buildGraphStructure(test)\n",
    "            \n",
    "            M = self.affinityMatrix_forward(F1, F2, U1, U2, G, G, H, H) #TODO: Build appropriate graph structure before using this\n",
    "            v = self.powerIteration_forward(M)\n",
    "            S = self.biStochastic_forward(v, G.shape[0], G.shape[0])\n",
    "            d = self.voting_forward(S, P) #Have to get P still\n",
    "            return d\n",
    "    def kronecker(self, matrix1, matrix2):\n",
    "        return torch.ger(matrix1.view(-1), matrix2.view(-1)).reshape(*(matrix1.size() + matrix2.size())).permute([0, 2, 1, 3]).reshape(matrix1.size(0) * matrix2.size(0), matrix1.size(1) * matrix2.size(1))\n",
    "\n",
    "\n",
    "    def buildGraphStructure(self, A):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "            - A: node-to-node adjaceny matrix\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            - G and H: node-edge incidence matrices such that: A = G*H^T\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get number of nodes\n",
    "        n = A.shape[0]\n",
    "\n",
    "        # Count number of ones in the adj. matrix to get number of edges\n",
    "        nr_edges = torch.sum(A)\n",
    "\n",
    "        # Init G and H\n",
    "        G = torch.zeros(n, nr_edges) \n",
    "        H = torch.zeros(n, nr_edges)\n",
    "\n",
    "        # Get all non-zero entries and build G and H\n",
    "        entries = (A != 0).nonzero()\n",
    "        for count, (i,j) in enumerate(entries, start=0):\n",
    "            G[i, count] = 1\n",
    "            H[j, count] = 1\n",
    "\n",
    "        return [G, H]\n",
    "\n",
    "\n",
    "    def affinityMatrix_forward(self, F1, F2, U1, U2, G1, G2, H1, H2):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "            - F1, F2: edge features of input image 1 and 2\n",
    "            - U1, U2: node features of input image 1 and 2\n",
    "            - G1, H1: node-edge incidence matrices of image 1\n",
    "            - G2, H2: node-edge incidence matrices of image 2\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "            - M: affinity Matrix computed according to the given formula\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        # (a) Build X and Y\n",
    "        #     - Get ordering of edges from G and H\n",
    "        #     - Extract edge features of start and end nodes and concat\n",
    "        idx1_start = (G1 != 0).nonzero()[:,0]\n",
    "        idx2_start = (G2 != 0).nonzero()[:,0]\n",
    "        idx1_end = (H1 != 0).nonzero()[:,0]\n",
    "        idx2_end = (H2 != 0).nonzero()[:,0]\n",
    "        X = torch.cat((F1[np.array(idx1_start)], F1[np.array(idx1_end)]), 1)\n",
    "        Y = torch.cat((F2[np.array(idx2_start)], F2[np.array(idx2_end)]), 1)\n",
    "\n",
    "        # (b) Calculate M_e = X * \\lambda * Y^T\n",
    "        M_e = torch.mm(torch.mm(X, self.lam), Y)\n",
    "\n",
    "        # (c) Calculate M_p = U1 * U2^T\n",
    "        M_p = torch.mm(U1, U2.t())\n",
    "\n",
    "        # Calculate M = [vec(M_p)] + (G_2 \\kronecker G_1)[vec(M_e)](H_2 \\kronecker H_1)^T\n",
    "        diagM_p = torchl.diag(M_p.view(M_p.numel()))\n",
    "        diagM_e = torchl.diag(M_e.view(M_e.numel()))\n",
    "        M = diagM_p + torch.mm(torch.mm(kronecker(G2, G1), diagM_e), kronecker(H2, H1).t())\n",
    "\n",
    "        return M\n",
    "\n",
    "    def powerIteration_forward(self, M, N = 1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "            - M: affinity matrix\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            - v*: optimal assignment vector (computed using power iterations) \n",
    "        \"\"\"\n",
    "\n",
    "        # Init starting v\n",
    "        v = torch.ones(M.shape[1],1)\n",
    "\n",
    "        # Perform N iterations: v_k+1 = M*v_k / (||M*v_k||_2) \n",
    "        for i in range(N):\n",
    "            v = torch.mv(M, v)\n",
    "            v = v / torch.norm(v, 2)\n",
    "\n",
    "        return tensor_v    \n",
    "\n",
    "\n",
    "    def biStochastic_forward(self, v, n, m, N = 1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "            - v:     optimal assignment vector\n",
    "            - n, m:  dimension of nodes of image 1 and image 2\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            - S:    double stochastic confidence matrix S\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reshape the assignment vector to matrix form\n",
    "        S = v.view(n,m)\n",
    "\n",
    "        # Perform N iterations: S_k+1 = ...., S_k+2 = ...\n",
    "        for i in range(N):\n",
    "            S = torch.mm(S, torch.mm(torch.ones(1,n),S).inverse())\n",
    "            S = torch.mm(torch.mv(S, torch.ones(m,1)).inverse(), S)\n",
    "\n",
    "        return S\n",
    "\n",
    "    def voting_forward(self, S, P, alpha = 200., th = 10):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "            S - confidence map obtained form bi-stochastic layer\n",
    "            P - Position matrix (m x 2)\n",
    "            alpha - scaling factor\n",
    "            th - number of pixels to be set as threshold beyond which confidence levels are set to zero.\n",
    "        Returns:\n",
    "        --------\n",
    "            - d: displacement vector\n",
    "\n",
    "        \"\"\"\n",
    "        S_ = alpha*S\n",
    "        #TODO: Apply th\n",
    "        P_ = torch.mm(F.softmax(S, dim = -1), P) \n",
    "        d = torch.zeros(P.shape)\n",
    "        for i in range(P.shape[0]):\n",
    "            d[:, i] = P_ -  P[:, i]\n",
    "\n",
    "        return d\n",
    "\n",
    "def loss(d, d_gt):\n",
    "    return torch.sum(torch.sqrt(torch.inner(d - d_gt, (d-d_gt).t()) + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Some tests\n",
    "# -----------\n",
    "test = torch.from_numpy(np.asarray([[1,0,1],[1,1,1],[1,0,0]]))\n",
    "[G, H] = buildGraphStructure(test)\n",
    "print(G)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = VGG_graph_matching().to(device)\n",
    "transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam\n",
      "features1.0.weight\n",
      "features1.0.bias\n",
      "features1.1.weight\n",
      "features1.1.bias\n",
      "features1.3.weight\n",
      "features1.3.bias\n",
      "features1.4.weight\n",
      "features1.4.bias\n",
      "features1.7.weight\n",
      "features1.7.bias\n",
      "features1.8.weight\n",
      "features1.8.bias\n",
      "features1.10.weight\n",
      "features1.10.bias\n",
      "features1.11.weight\n",
      "features1.11.bias\n",
      "features1.14.weight\n",
      "features1.14.bias\n",
      "features1.15.weight\n",
      "features1.15.bias\n",
      "features1.17.weight\n",
      "features1.17.bias\n",
      "features1.18.weight\n",
      "features1.18.bias\n",
      "features1.20.weight\n",
      "features1.20.bias\n",
      "features1.21.weight\n",
      "features1.21.bias\n",
      "features1.24.weight\n",
      "features1.24.bias\n",
      "features1.25.weight\n",
      "features1.25.bias\n",
      "features1.27.weight\n",
      "features1.27.bias\n",
      "features1.28.weight\n",
      "features1.28.bias\n",
      "features1.30.weight\n",
      "features1.30.bias\n",
      "features1.31.weight\n",
      "features1.31.bias\n",
      "features2.1.weight\n",
      "features2.1.bias\n",
      "features2.2.weight\n",
      "features2.2.bias\n",
      "features2.4.weight\n",
      "features2.4.bias\n",
      "features2.5.weight\n",
      "features2.5.bias\n",
      "features2.7.weight\n",
      "features2.7.bias\n",
      "features2.8.weight\n",
      "features2.8.bias\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(width, height, grid_size = 10): \n",
    "    \"\"\"\n",
    "    Get the location based on the image size corresponding to relu_4_2 \n",
    "    and relu_5_1 layer for a desired grid size. \n",
    "    \"\"\"\n",
    "    x_jump = int(width/grid_size) \n",
    "    y_jump = int(height/grid_size)\n",
    "    x_idx = np.linspace(int(x_jump/2),int(width - x_jump/2), grid_size, dtype = np.int32)\n",
    "    y_idx = np.linspace(int(y_jump/2), int(height - y_jump/2), grid_size, dtype = np.int32)\n",
    "    f_mask = torch.zeros((height//(2**4),width//2**4)).byte()\n",
    "    u_mask = torch.zeros((height//(2**3),width//2**3)).byte()\n",
    "    for i in x_idx:\n",
    "        for j in y_idx:\n",
    "            f_mask[j//(2**4),i//(2**4)] = 1\n",
    "            u_mask[j//(2**3),i//(2**3)] = 1\n",
    "    return(u_mask, f_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optim_vgg = nn.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "im1 = Image.open(image1).convert('RGB') \n",
    "im2 = Image.open(image2).convert('RGB') \n",
    "im1 = transformation(im1).unsqueeze_(0)\n",
    "im2 = transformation(im2).unsqueeze_(0)\n",
    "mask_1 = get_mask(im1.size[0],im1.size[1])\n",
    "mask_1 = get_mask(im2.size[0],im2.size[1])\n",
    "\n",
    "d = model(im1, mask1, im2, mask2) \n",
    "\n",
    "loss = loss(d, d_gt) #To be implemented\n",
    "loss.backward()\n",
    "optim_vgg.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
